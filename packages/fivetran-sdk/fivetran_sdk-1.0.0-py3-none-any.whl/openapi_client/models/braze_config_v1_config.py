# coding: utf-8

"""
    OpenAPI Definition

    The OpenAPI Specification is a standard format to define the structure and syntax of REST APIs. OpenAPI documents are both machine and human-readable, which enables anyone to easily determine how each API works. [More details](https://www.openapis.org/faq)

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, Field, SecretStr, StrictBool, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing import Optional, Set
from typing_extensions import Self

class BrazeConfigV1Config(BaseModel):
    """
    
    """ # noqa: E501
    var_schema: Optional[StrictStr] = Field(default=None, description="Destination schema. Schema is permanent and cannot be changed after connection creation", alias="schema")
    gcs_folder: Optional[StrictStr] = Field(default=None, description="Your GCS folder name. Required if `GCS` is the `cloud_storage_type`")
    s3_export_bucket: Optional[StrictStr] = Field(default=None, description="Exports Bucket")
    api_url: Optional[StrictStr] = Field(default=None, description="Your Braze API URL.")
    gcs_bucket: Optional[StrictStr] = Field(default=None, description="Your GCS bucket. Required if `GCS` is the `cloud_storage_type`")
    s3_export_role_arn: Optional[SecretStr] = Field(default=None, description="Exports Role ARN")
    abs_container_name: Optional[StrictStr] = Field(default=None, description="Container Name")
    s3external_id: Optional[StrictStr] = Field(default=None, description="This is the same as your `group_id`, used for authentication along with the `role_arn` required if `AWS_S3` is the `cloud_storage_type`")
    s3_export_folder: Optional[StrictStr] = Field(default=None, description="Exports Folder")
    s3folder: Optional[StrictStr] = Field(default=None, description="Your S3 folder name required if `AWS_S3` is the `cloud_storage_type`")
    abs_prefix: Optional[StrictStr] = Field(default=None, description="Prefix")
    enable_exports: Optional[StrictBool] = Field(default=None, description="Enable User Profile Exports")
    cloud_storage_type: Optional[Dict[str, Any]] = Field(default=None, description="Cloud storage type Braze Current is connected to.")
    export_storage_type: Optional[Dict[str, Any]] = Field(default=None, description="Export Storage")
    s3role_arn: Optional[SecretStr] = Field(default=None, description="The Role ARN required for authentication required if `AWS_S3` is the `cloud_storage_type`")
    abs_connection_string: Optional[SecretStr] = Field(default=None, description="Connection String")
    s3bucket: Optional[StrictStr] = Field(default=None, description="Your S3 bucket required if `AWS_S3` is the `cloud_storage_type`")
    api_key: Optional[SecretStr] = Field(default=None, description="Your Braze API Key.")
    __properties: ClassVar[List[str]] = ["schema", "gcs_folder", "s3_export_bucket", "api_url", "gcs_bucket", "s3_export_role_arn", "abs_container_name", "s3external_id", "s3_export_folder", "s3folder", "abs_prefix", "enable_exports", "cloud_storage_type", "export_storage_type", "s3role_arn", "abs_connection_string", "s3bucket", "api_key"]

    @field_validator('cloud_storage_type')
    def cloud_storage_type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in ('AZURE_BLOB_STORAGE', 'GCS', 'NONE', 'AWS_S3'):
            raise ValueError("must be one of enum values ('AZURE_BLOB_STORAGE', 'GCS', 'NONE', 'AWS_S3')")
        return value

    @field_validator('export_storage_type')
    def export_storage_type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in ('AZURE_BLOB_STORAGE', 'GCS', 'NONE', 'AWS_S3'):
            raise ValueError("must be one of enum values ('AZURE_BLOB_STORAGE', 'GCS', 'NONE', 'AWS_S3')")
        return value

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True,
        "protected_namespaces": (),
    }


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of BrazeConfigV1Config from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of BrazeConfigV1Config from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "schema": obj.get("schema"),
            "gcs_folder": obj.get("gcs_folder"),
            "s3_export_bucket": obj.get("s3_export_bucket"),
            "api_url": obj.get("api_url"),
            "gcs_bucket": obj.get("gcs_bucket"),
            "s3_export_role_arn": obj.get("s3_export_role_arn"),
            "abs_container_name": obj.get("abs_container_name"),
            "s3external_id": obj.get("s3external_id"),
            "s3_export_folder": obj.get("s3_export_folder"),
            "s3folder": obj.get("s3folder"),
            "abs_prefix": obj.get("abs_prefix"),
            "enable_exports": obj.get("enable_exports"),
            "cloud_storage_type": obj.get("cloud_storage_type"),
            "export_storage_type": obj.get("export_storage_type"),
            "s3role_arn": obj.get("s3role_arn"),
            "abs_connection_string": obj.get("abs_connection_string"),
            "s3bucket": obj.get("s3bucket"),
            "api_key": obj.get("api_key")
        })
        return _obj


