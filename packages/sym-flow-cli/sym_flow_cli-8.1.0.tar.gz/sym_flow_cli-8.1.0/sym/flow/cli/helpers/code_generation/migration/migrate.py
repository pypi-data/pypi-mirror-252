import difflib
import importlib.resources as pkg_resources
import re
import shutil
import subprocess
from datetime import datetime
from pathlib import Path
from typing import List
from zipfile import ZipFile

import click
import hcl2

import sym.flow.cli.helpers.output as cli_output
from sym.flow.cli.code_generation_templates.migration import v8
from sym.flow.cli.helpers.code_generation.core import FlowGeneration
from sym.flow.cli.helpers.code_generation.migration.moved_block import MovedBlock
from sym.flow.cli.helpers.global_options import GlobalOptions
from sym.flow.cli.helpers.terraform import get_terraform_local_variable


class CodeGenerationMigrator(FlowGeneration):
    """A utility class that helps with migrating Terraform generated by previous versions to be compatible with
    the current version.

    Note: Inherits from FlowGeneration so it has access to all utility functions to generate connectors and other files.
    """

    def __init__(self, options: GlobalOptions, working_directory: str, target_directory: str) -> None:
        """
        Args:
            options: A GlobalOptions object to handle debug printing
            working_directory: A temporary directory containing a copy of the *.tf files to migrate.
            target_directory: The target directory containing the actual files to be modified.
        """
        super().__init__(flow_name="", directory=working_directory)

        self.options = options
        self.target_directory = target_directory

        # An array of moved blocks to add to the generated migration_v8.tf file.
        self.moved_blocks: List[MovedBlock] = []

    @property
    def migration_filepath(self) -> str:
        return f"{self.working_directory}/migration_v8.tf"

    @property
    def runtime_tf_moved_blocks(self) -> List[MovedBlock]:
        return [
            MovedBlock(
                moved_from="random_uuid.external_id", moved_to="module.runtime_connector.random_uuid.external_id"
            ),
            MovedBlock(
                moved_from="aws_iam_role.sym_runtime_connector_role",
                moved_to="module.runtime_connector.aws_iam_role.this",
            ),
            MovedBlock(
                moved_from="aws_iam_policy.assume_roles",
                moved_to="module.runtime_connector.aws_iam_policy.assume_roles",
            ),
            MovedBlock(
                moved_from="aws_iam_role_policy_attachment.attach_assume_roles",
                moved_to="module.runtime_connector.aws_iam_role_policy_attachment.assume_roles_attach",
            ),
            MovedBlock(
                moved_from="sym_integration.runtime_context",
                moved_to="module.runtime_connector.sym_integration.runtime_context",
            ),
        ]

    @property
    def secrets_tf_moved_blocks(self) -> List[MovedBlock]:
        return [
            MovedBlock(
                moved_from="aws_iam_policy.secrets_manager_access",
                moved_to="module.secrets_manager_access.aws_iam_policy.this",
            ),
            MovedBlock(
                moved_from="aws_iam_role_policy_attachment.attach_secrets_manager_access",
                moved_to="module.secrets_manager_access.aws_iam_role_policy_attachment.attach_secrets_manager_access[0]",
            ),
        ]

    def sym_runtime_moved_block(self, resource_name: str) -> MovedBlock:
        return MovedBlock(
            moved_from=f"sym_runtime.{resource_name}", moved_to="module.runtime_connector.sym_runtime.this"
        )

    def migrate_connector_modules(self):
        """Migrates any existing runtime.tf and connectors.tf files.

        1. If a runtime.tf file exists, generates a connectors.tf with the new runtime_connector module
        2. Preserves any existing connector declarations if a connectors.tf already exists.
        """

        # Collect all the connectors that will need to be added to the new connectors.tf
        connector_modules = []

        # If a connectors.tf already exists, save any existing connector modules so we can redeclare them.
        if Path(self.connectors_tf_filepath).exists():
            self.options.dprint(f"Parsing connectors.tf...")
            with open(self.connectors_tf_filepath, "r") as f:
                # If connectors.tf was generated by this version of symflow, then we shouldn't need to make any migrations.
                if "symflow CLI v8" in f.read():
                    self.options.dprint(
                        "'connectors.tf' was generated by symflow v8. No changes required for 'connectors.tf'."
                    )
                    return

                f.seek(0)
                connectors_tf = hcl2.load(f)

            # Save the names of the modules declared in this file.
            for module in connectors_tf["module"]:
                # module is a dict of one key/value pair, where the key is the module name.
                # set(module) turns it into a set of keys,
                # set(module).pop() gives us the module name.
                connector_modules.append(set(module).pop())

            # If the aws_region is declared in this file, then save it.
            if aws_region := get_terraform_local_variable(connectors_tf, "aws_region"):
                self.options.dprint(f"Setting 'aws_region' to {aws_region}.")
                self.aws_region = aws_region

            # Remove the existing connectors.tf file so we can regenerate it in the v8 format.
            Path(self.connectors_tf_filepath).unlink()

        # If a runtime.tf exists, we need to generate a runtime_module, and a fresh connectors.tf that contains
        # the aws provider definition.
        if Path(self.deprecated_runtime_tf_filepath).exists():
            with open(self.deprecated_runtime_tf_filepath) as f:
                runtime_tf = hcl2.load(f)

            if not self.aws_region:
                # If we don't have an AWS region set already, try to get it from this file.
                self.options.dprint("Parsing 'runtime.tf' for 'aws_region'...")
                if not (aws_region := get_terraform_local_variable(runtime_tf, "aws_region")):
                    self.fail_migration("Failed to migrate 'runtime.tf'! No 'aws_region' found in locals block.")

                # Set the AWS region on the migrator class so we can generate a new connectors.tf
                self.options.dprint(f"Setting 'aws_region' to {aws_region}.")
                self.aws_region = aws_region

            # Add the runtime_connector to the list of generated modules.
            if "sso_connector" in connector_modules:
                # If the SSO connector exists, generate a runtime_connector that includes the SSO Account ID
                connector_modules.insert(0, "runtime_connector_with_account_id_safelist")
            else:
                # Otherwise declare a standard runtime_connector module.
                connector_modules.insert(0, "runtime_connector")

            # Add `runtime.tf` to the list of moved blocks to generate
            self.moved_blocks.extend(self.runtime_tf_moved_blocks)

            # If a sym_runtime resource exists, add a "moved" block for it as well.
            if sym_runtime := next((r["sym_runtime"] for r in runtime_tf["resource"] if "sym_runtime" in r), None):
                # Get the resource name of the sym_runtime resource
                # (i.e. resource "sym_runtime" "resource_name" { ... })
                # Note: `sym_runtime` here is a dict with one key/value pair, where the key is the resource name.
                resource_name = set(sym_runtime).pop()
                self.moved_blocks.append(self.sym_runtime_moved_block(resource_name))

            # Remove the runtime.tf file. It is no longer generated in v8
            self.options.dprint(f"Deleting 'runtime.tf'.")
            Path(self.deprecated_runtime_tf_filepath).unlink()

        # Generate a new connectors.tf containing all the connector_modules
        self.options.dprint(f"Generating 'connectors.tf' with the following modules: {connector_modules}")
        for connector_module in connector_modules:
            self._append_connector_module(connector_module)

        self.options.dprint("Finished migrating 'runtime.tf' and 'connectors.tf' configurations.")

    def migrate_secrets_tf(self):
        """Migrates any existing secrets.tf file to use the secretsmgr-addon module."""
        if Path(self.secrets_tf_filepath).exists():
            self.options.dprint("Migrating 'secrets.tf'...")
            with open(self.secrets_tf_filepath) as f:
                # If secrets.tf was generated by this version of symflow, then we shouldn't need to make any migrations.
                if "symflow CLI v8" in f.read():
                    self.options.dprint(
                        "'secrets.tf' was generated by symflow v8. No changes required for 'secrets.tf'."
                    )
                    return

            # Delete the existing secrets.tf and regenerate it.
            Path(self.secrets_tf_filepath).unlink()
            self._generate_secrets_tf()

            # Add `secrets.tf` to the list of moved blocks to generate
            self.moved_blocks.extend(self.secrets_tf_moved_blocks)

            self.options.dprint("Finished migrating 'secrets.tf'.")

    def refactor_references(self):
        """
        1. Replaces any references to `aws_iam_role.sym_runtime_connector_role` with
            `module.runtime_connector.sym_runtime_connector_role`
        2. Replaces any references to `sym_runtime.<runtime-name>` with `module.runtime_connector.sym_runtime`
        3. Replaces the "symflow CLI v7.x.x on <timestamp> UTC" comment in files with the current version and timestamp.
        """
        self.options.dprint("Updating references to sym_runtime_connector_role and sym_runtime...")
        for file_path in Path(self.working_directory).iterdir():
            self.options.dprint(f"Migrating {file_path.name}...")
            with open(file_path, "r+") as f:
                # Read all file contents as a string
                contents = f.read()

                # Replace aws_iam_role.sym_runtime_connector_role references
                self.options.dprint("Replacing references to aws_iam_role.sym_runtime_connector_role...")
                contents = contents.replace(
                    "aws_iam_role.sym_runtime_connector_role", "module.runtime_connector.sym_runtime_connector_role"
                )

                # Update any sym_runtime references
                self.options.dprint("Replacing references to sym_runtime...")
                runtime_id_regex = r"sym_runtime\..*\.id"
                contents = re.sub(runtime_id_regex, "module.runtime_connector.sym_runtime.id", contents)

                # Replace symflow CLI version everywhere
                self.options.dprint("Updating symflow CLI version and generation timestamp...")
                generated_by_regex = r"symflow CLI v7.* on .* UTC"
                formatted_time = datetime.utcnow().strftime("%Y-%m-%d at %H:%M")
                contents = re.sub(
                    generated_by_regex, f"symflow CLI v{self.symflow_version} on {formatted_time} UTC", contents
                )

                # Rewrite the updated contents to the file
                self.options.dprint(f"Writing updated configuration to {file_path.name}...")
                f.seek(0)
                f.write(contents)
                f.truncate()
            self.options.dprint(f"Finished migrating {file_path.name}.")

    def generate_moved_blocks(self):
        """Creates a `migration_v8.tf` file containing Terraform `moved` blocks to transform any existing Terraform
        state to match the new configuration.
        """
        if not self.moved_blocks:
            # Don't generate a migration_v8.tf file if we don't have any moved blocks to generate.
            return

        with open(self.migration_filepath, "w") as f:
            # Write the header comments
            migration_v8_tf = self._format_template(pkg_resources.read_text(v8, "migration_v8.tf"))
            f.write(migration_v8_tf)

            # Write each moved block.
            for moved_block in self.moved_blocks:
                f.write(moved_block.to_terraform())

            # Ensure there's a trailing newline at the end of the file
            f.write("\n")

    def validate_migration(self):
        """Attempts a light validation of the generated configuration files by running `terraform fmt`,
        which will raise errors if the configuration has syntax errors.
        """

        self.options.dprint("Validating that migrated code is valid Terraform...")
        try:
            # Try to run terraform fmt with -write=false, so we don't reformat files.
            # This errors only if the code is syntactically incorrect.
            # If it succeeds, then the generated configuration is valid syntax.
            subprocess.run(
                ["terraform", "fmt", "-write=false", self.working_directory], check=True, capture_output=True
            )
        except subprocess.CalledProcessError as e:
            # `terraform fmt` returned a nonzero exit code, indicating that the syntax was invalid.
            # Don't apply the migration. Print an error and redirect the user to the docs to manually migrate.
            self.options.dprint(f"Terraform fmt failed with exit code {e.returncode} and error:")
            self.options.dprint(e.stderr)
            self.fail_migration("The migration failed to produce valid Terraform. No changes were applied.")
        except OSError:
            # Terraform executable not found. Instead of failing, we will continue the migration, but print a warning.
            cli_output.warn(
                "The syntax of the migrated configuration could be not validated, because the executable "
                "'terraform' was not found! Please confirm that the configuration is valid before applying."
            )

    def backup_existing_files(self) -> str:
        """Generates a zip containing the .terraform.lock.hcl, *.tf files, *.tfvars files, *.tfstate file, and
        impls/ and *_lambda_src/ subdirectories in the target directory before the migration is applied.

        Returns: The filepath of the generated zip file
        """
        zip_name = datetime.utcnow().strftime("symflow-migrate-backup-%Y-%m-%d-%H-%M-%S.zip")
        backup_path = f"{self.target_directory}/{zip_name}"

        self.options.dprint(f"Backing up {self.target_directory} contents into {backup_path}")
        with ZipFile(backup_path, "w") as backup:

            # Back up the regular files
            for file_pattern in {"*.tf", "*.tfstate", ".terraform.lock.hcl", "*.tfvars"}:
                for tf_filepath in Path(self.target_directory).glob(file_pattern):
                    # arcname is the path relative to the archive root
                    # Because these should all be toplevel files, the arcname is just the final component of the path
                    self.options.dprint(f"Backing up {tf_filepath}")
                    backup.write(filename=tf_filepath, arcname=tf_filepath.name)

            # Backup the impls/ directory
            if (Path(self.target_directory) / "impls").is_dir():
                for impl_path in (Path(self.target_directory) / "impls").iterdir():
                    self.options.dprint(f"Backing up {impl_path}")
                    # These files should all be nested under the impls subdirectory
                    backup.write(filename=impl_path, arcname=f"impls/{impl_path.name}")

            # Backup any *_lambda_src/ directories
            for lambda_src_dir in Path(self.target_directory).glob("*_lambda_src/"):
                # Check that the path is actually a directory, then backup all the files
                if lambda_src_dir.is_dir():
                    self.options.dprint(f"Backing up {lambda_src_dir}")
                    for lambda_src_file in lambda_src_dir.iterdir():
                        backup.write(filename=lambda_src_file, arcname=f"{lambda_src_dir.name}/{lambda_src_file.name}")

        self.options.dprint(f"Finished backing up {self.target_directory} contents into {backup_path}")
        return backup_path

    def generate_diff(self) -> str:
        total_diff: List[str] = []
        original_filenames = set(f.name for f in Path(self.target_directory).glob("*.tf"))
        migrated_filenames = set(f.name for f in Path(self.working_directory).glob("*.tf"))

        deleted_files = original_filenames.difference(migrated_filenames)
        created_files = migrated_filenames.difference(original_filenames)
        updated_files = original_filenames.intersection(migrated_filenames)

        for filename in updated_files:
            with open(Path(self.target_directory) / filename, "r") as f:
                original_filelines = f.readlines()
            with open(Path(self.working_directory) / filename, "r") as f:
                updated_filelines = f.readlines()

            if original_filelines != updated_filelines:
                diff = difflib.unified_diff(
                    original_filelines, updated_filelines, f"original/{filename}", f"migrated/{filename}"
                )
                total_diff.extend(diff)
                total_diff.append("\n")

        for filename in created_files:
            with open(Path(self.working_directory) / filename, "r") as f:
                updated_filelines = f.readlines()
            total_diff.extend(
                difflib.unified_diff([], updated_filelines, f"original/{filename}", f"migrated/{filename}")
            )
            total_diff.append("\n")

        for filename in deleted_files:
            with open(Path(self.target_directory) / filename, "r") as f:
                original_filelines = f.readlines()
            total_diff.extend(
                difflib.unified_diff(original_filelines, [], f"original/{filename}", f"migrated/{filename}")
            )
            total_diff.append("\n")

        return "".join(self._color_diff(total_diff))

    def _color_diff(self, diff: List[str]):
        for line in diff:
            if line.startswith("+"):
                yield click.style(line, fg="green")
            elif line.startswith("-"):
                yield click.style(line, fg="red")
            elif line.startswith("@"):
                yield click.style(line, fg="blue")
            else:
                yield line

    def apply_migration(self):
        """Applies the migrations from the temporary working directory into the target directory."""
        self.options.dprint(f"Applying changes to target directory: {self.target_directory}")
        # Remove the old runtime.tf file from the target directory, it no longer exists in v8
        Path(f"{self.target_directory}/runtime.tf").unlink(missing_ok=True)

        # Overwriting all the *.tf files in the target directory with the *.tf files in the working directory
        shutil.copytree(self.working_directory, self.target_directory, dirs_exist_ok=True)

    def fail_migration(self, error: str):
        """Fails the migration and exits the CLI with the given error message and a link to the docs for manual
        migration instructions.
        """
        message = (
            f"{error}\n\nVisit the docs for instructions on how to migrate your configuration manually: "
            "https://docs.symops.com/docs/migrating-generated-files-from-symflow-v7-to-v8"
        )

        # Don't show the hint about --debug if the command was already run with the --debug flag.
        if not self.options.debug:
            hint = "To see detailed error messages, you can try re-running the command as `symflow --debug migrate`."
        else:
            hint = None

        cli_output.fail(message, hint=hint)

    # NOT IMPLEMENTED METHODS
    # The following methods are required to be implemented by the FlowGeneration superclass, but are not relevant
    # in the context of the CodeGenerationMigrator, which only extends the FlowGeneration superclass so that it has
    # access to code generation helper methods.
    @classmethod
    def get_flow_tf_filepath(cls, flow_name: str, working_directory: str = ".") -> str:
        raise NotImplementedError("CodeGenerationMigrator should not generate Flow configuration files.")

    def generate(self) -> None:
        raise NotImplementedError("CodeGenerationMigrator does not support the generate method.")

    @property
    def impl_filepath(self) -> str:
        raise NotImplementedError("CodeGenerationMigrator cannot not generate implementation files.")
