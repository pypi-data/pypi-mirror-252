{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "373e997d",
   "metadata": {},
   "source": [
    "# Logging device states and test results to a database\n",
    "A number of tools are included in `labbench` to streamline acquisition of test data into a database. A couple of methods are\n",
    "\n",
    "* Automatically monitoring attributes in `state` and logging changes\n",
    "* Saving postprocessed data in the as a new column\n",
    "\n",
    "The data management supports automatic relational databasing. Common non-scalar data types (`pandas.DataFrame`, `numpy.array`, long strings, files generated outside of the data tree, etc.) are automatically stored relationally --- placed in folders and referred to in the database. Other data can be forced to be relational by dynamically generating relational databases on the fly.\n",
    "\n",
    "## File conventions\n",
    "All labbench data save functionality is implemented in tables with [pandas](http://pandas.pydata.org) DataFrame backends. Here are database storage formats that are supported:\n",
    "\n",
    "| Format                            | File extension(s)              | Data management class | flag to [use record file format](http://ssm.ipages.nist.gov/labbench/labbench.html#labbench.managedata.RelationalTableLogger.set_relational_file_format) | Comments |\n",
    "|:----------------------------------|:-------------------------------|:-----------------------|:------------------------|:----\n",
    "| [sqlite](http://sqlite.org/)              | .db                            | [labbench.SQLiteLogger](http://ssm.ipages.nist.gov/labbench/labbench.html#labbench.managedata.SQLiteLogger) | 'sqlite' | Scales to larger databases than csv |\n",
    "| csv                               | .csv,.csv.gz,.csv.bz2,.csv.zip | [labbench.CSVLogger](http://ssm.ipages.nist.gov/labbench/labbench.html#labbench.managedata.CSVLogger)          |'csv'| Easy to inspect |\n",
    "\n",
    "Several formats are supported only as relational data (data stored in a file in the subdirectory instead of directly in the ). Certain types of data as values into the database manager automatically become relational data when you call the `append` method of the data manager:\n",
    "\n",
    "| Format                            | File extension(s)              | python type conversion | [set_record file format](http://ssm.ipages.nist.gov/labbench/labbench.html#labbench.managedata.RelationalTableLogger.set_relational_file_format) flag | Comments |\n",
    "|:----------------------------------|:-------------------------------|:-----------------------|:------------------------|:----\n",
    "| [feather](http://github.com/wesm/feather)| .f                             | iterables of numbers and strings; pd.DataFrame | 'feather' | Python 3.x only\n",
    "| [json](http://www.json.org/)      | .json                          | iterables of numbers and strings; pd.DataFrame         | 'json' | |\n",
    "| csv                               | .csv | iterables of numbers and strings; pd.DataFrame         |'csv'| |\n",
    "| python [pickle](https://docs.python.org/3/library/pickle.html) | .pickle | any | 'pickle' | fallback if the chosen relational format fails |\n",
    "| text files     | .txt | string or bytes longer than `text_relational_min` | N/A | set `text_relational_min` when you instantiate the database manager\n",
    "| arbitrary files generated outside the file tree |     *             | strings containing filesystem path | N/A |\n",
    "\n",
    "In the following example, we will use an sqlite master database, and csv record files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35202e0",
   "metadata": {},
   "source": [
    "## Example\n",
    "Here is a emulated \"dummy\" instrument. It has a few state settings similar to a simple power sensor. The state descriptors (`initiate_continuous`, `output_trigger`, etc.) are defined as local types, which means they don't trigger communication with any actual devices. The `fetch_trace` method generates a \"trace\" drawn from a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c72eed40",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'labbench' has no attribute 'EmulatedVISADevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEmulatedInstrument\u001b[39;00m(\u001b[43mlb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmulatedVISADevice\u001b[49m):\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" This \"instrument\" makes mock data and instrument states to\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m        demonstrate we can show the process of setting\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m        up a measurement.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mstate\u001b[39;00m (lb\u001b[38;5;241m.\u001b[39mEmulatedVISADevice\u001b[38;5;241m.\u001b[39mstate):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'labbench' has no attribute 'EmulatedVISADevice'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "import labbench as lb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class EmulatedInstrument(lb.EmulatedVISADevice):\n",
    "    \"\"\" This \"instrument\" makes mock data and instrument states to\n",
    "        demonstrate we can show the process of setting\n",
    "        up a measurement.\n",
    "    \"\"\"\n",
    "    class state (lb.EmulatedVISADevice.state):\n",
    "        initiate_continuous:bool = attr.property(key='INIT:CONT')\n",
    "        output_trigger:bool = attr.property(key='OUTP:TRIG')\n",
    "        sweep_aperture:float = attr.property(min=20e-6, max=200e-3,help='s')\n",
    "        frequency:float = attr.property(min=10e6, max=18e9,step=1e-3,help='Hz')\n",
    "\n",
    "    def trigger(self):\n",
    "        \"\"\" This would tell the instrument to start a measurement\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def fetch_trace(self, N=1001):\n",
    "        \"\"\" Generate N points of junk data as a pandas series.\n",
    "        \"\"\"\n",
    "        values = np.random.normal(size=N)\n",
    "        index = np.linspace(0,self.state.sweep_aperture,N)\n",
    "        series = pd.Series(values,index=index,name='voltage')\n",
    "        series.index.name = 'time'\n",
    "        return series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be2e3e",
   "metadata": {},
   "source": [
    "Now make a loop to execute 100 test runs with two emulated instruments, and log the results with a relational SQLite database. I do a little setup to start:\n",
    "\n",
    "1. Define a couple of functions `inst1_trace` and `inst2_trace` that collect my data\n",
    "2. Instantiate 2 instruments, `inst1` and `inst2`\n",
    "3. Instantiate the logger with `lb.SQLiteLogger('test.db', 'state')`.\n",
    "   The arguments specify the name of the sqlite database file and the name of the table where the following will be stored: 1) the instrument state info will be stored, 2) locations of data files, and 3) any extra comments we add with `db.write()`.\n",
    "\n",
    "Remember that use of the `with` statement automatically connects to the instruments, and then ensures that the instruments are properly closed when we leave the `with` block (even if there is an exception)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inst1_trace ():\n",
    "    \"\"\" Return a 1001-point trace\n",
    "    \"\"\"\n",
    "    inst1.trigger()\n",
    "    return inst1.fetch_trace(51)\n",
    "\n",
    "def inst2_trace ():\n",
    "    \"\"\" This one returns only one point\n",
    "    \"\"\"\n",
    "    inst2.trigger()\n",
    "    return inst2.fetch_trace(1).values[0]\n",
    "    \n",
    "# Root directory of the database\n",
    "db_path = r'data'\n",
    "\n",
    "# Seed the data dictionary with some global data\n",
    "data = {'dut': 'DUT 15'}\n",
    "\n",
    "Nfreqs = 101\n",
    "\n",
    "with EmulatedInstrument()        as inst1,\\\n",
    "     EmulatedInstrument()        as inst2,\\\n",
    "     lb.SQLiteLogger(db_path)  as db:\n",
    "        # Catch any changes in inst1.state and inst2.state\n",
    "        db.observe_states([inst1,inst2])  \n",
    "        \n",
    "        # Update inst1.state.sweep_aperture on each db.append\n",
    "        db.observe_states(inst1, always='sweep_aperture')\n",
    "        \n",
    "        # Store trace data in csv format\n",
    "        db.set_relational_file_format('csv')\n",
    "        \n",
    "        # Perform a frequency sweep. The frequency will be logged to the\n",
    "        # database, because we configured it to observe all state changes.\n",
    "        inst2.state.frequency = 5.8e9\n",
    "        for inst1.state.frequency in np.linspace(5.8e9, 5.9e9, Nfreqs):                    \n",
    "            # Collect \"test data\" by concurrently calling\n",
    "            # inst1_trace and inst2_trace\n",
    "            data.update(lb.concurrently(inst1_trace, inst2_trace))\n",
    "\n",
    "            # Append the new data as a row to the database.\n",
    "            # Each key is a column in the database (which will be added\n",
    "            # dynamically to the database if needed). More keys and values\n",
    "            # are also added corresponding to attributes inst1.state and inst2.state\n",
    "            db.append(comments='trying for 1.21 GW to time travel',\n",
    "                      **data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f470e",
   "metadata": {},
   "source": [
    "### Reading and exploring the data\n",
    "The master database is now populated with the test results and subdirectories are populated with trace data. `labbench` provides the function `read` as a shortcut to load the sqlite database into a pandas dataframe. Each state is a column in the database. The logger creates columns named as a combination of the device name ('inst1') and name of the corresponding device state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c63cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "master = lb.read(f'{db_path}/master.db')\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab52a170",
   "metadata": {},
   "source": [
    "This is a pandas DataFrame object. There is extensive information about how to use dataframes [on the pandas website](http://pandas.pydata.org/pandas-docs/stable/). Suppose we want to bring in the data from the traces, which are in a collection of waveform files specified under the `inst1_trace` column. The function `labbench.expand` serves to flatten the database with respect to data files that were generated on each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97fda9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = lb.read_relational(f'{db_path}/master.db', 'inst1_trace', ['dut', 'inst1_frequency'])\n",
    "waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c2ed6",
   "metadata": {},
   "source": [
    "now we can manipulate the results to look for meaningful information in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5706d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set(context='notebook', style='ticks', font_scale=1.5) # Theme stuff\n",
    "\n",
    "waveforms.plot(x='inst1_frequency',y='inst1_trace_voltage',kind='hexbin')\n",
    "xlabel('Frequency (Hz)')\n",
    "ylabel('Voltage (arb units)')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.15.1"
   }
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "source_map": [
   12,
   43,
   48,
   79,
   90,
   137,
   142,
   146,
   150,
   153,
   157
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}